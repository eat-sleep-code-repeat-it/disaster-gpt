
#  DisasterGPT â€“ Ask Anything About U.S. Disaster Declarations

 
```bash
# Python 3.13.7

python -m venv venv
venv\Scripts\activate 

pip install gradio
pip install openai
pip install faiss-cpu
pip install python-dotenv

pip freeze > requirements.txt

# set OPENAI_API_KEY in .env file
python disaster_gpt.py
```

## Sample questions
```js
is there an active disaster in Washington County, Oregon?
is there an disaster in Riverside, California?
is there an active disaster in Riverside, California? 
active fire disasters?
``

## âœ… What we Get:
- A clean chat UI (like ChatGPT)
- Each message sends a user query
- RAG pipeline is run
    - create index and save it to local vector file
    - or load index from the saved vector file
- Assistant returns a structured answer using openai
- Built with Guardrail and evaluation
- Previous messages are preserved in context

## Suggested Project Structure
```bash
disaster-gpt/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py               # ðŸ”¹ Main Gradio app (entry point)
â”‚   â”œâ”€â”€ rag_pipeline.py       # ðŸ”¹ RAG logic (retrieval + answer generation)
â”‚   â”œâ”€â”€ models.py             # ðŸ”¹ Pydantic models (e.g., DisasterDeclaration)
â”‚   â”œâ”€â”€ embedding_utils.py    # ðŸ”¹ Embedding + FAISS index handling
â”‚   â”œâ”€â”€ answer_eval.py        # ðŸ”¹ Guardrails & GPT-based evaluation
â”‚   â”œâ”€â”€ data_loader.py        # ðŸ”¹ Load/parse CSV data
â”‚   â””â”€â”€ constants.py          # ðŸ”¹ Paths, constants, config keys
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ disaster_declarations.csv  # ðŸ”¹ Source dataset
â”‚
â”œâ”€â”€ saved_index/              # ðŸ”¹ Store FAISS index & metadata
â”‚   â”œâ”€â”€ disaster_faiss.index
â”‚   â””â”€â”€ disaster_metadata.pkl
â”‚
â”œâ”€â”€ assets/                   # ðŸ”¹ (Optional) Images, logos, docs
â”‚   â””â”€â”€ logo.png
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_rag_pipeline.py  # ðŸ”¹ Unit tests (pytest)
â”‚
â”œâ”€â”€ .env                      # ðŸ”¹ OpenAI keys, etc.
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ run.sh                    # ðŸ”¹ Simple launcher (optional)


app/main.py	Launches the Gradio UI (e.g., gr.ChatInterface)
app/rag_pipeline.py	Contains rag_pipeline() and chat_rag_fn() logic
app/models.py	Pydantic DisasterDeclaration and other data models
app/embedding_utils.py	Embedding + FAISS build/save/load
app/answer_eval.py	GPT-based evaluation and keyword-based guardrails
data/	Static data source (e.g., CSVs)
saved_index/	Stores generated FAISS index and metadata
tests/	Optional test suite using pytest or unittest
This structure:

Keeps Gradio app logic clean and isolated
Separates data/model logic from UI
Makes it easier to maintain, extend, or even deploy later (e.g., with FastAPI or Streamlit)
```

